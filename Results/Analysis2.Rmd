---
title: "Analysis2"
author: "Matteo Rossi"
date: "2023-11-26"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Importing the libraries

```{r}
library(readxl)
library(dplyr)
library(metafor)
```


## Reading and Cleaning the dataframe

```{r}
df = read_excel("PaperCharacterizationTable_Meta.xlsx",
                sheet = "Metacognition",
                skip = 1)

df = df %>% select(-starts_with('...'))

colnames(df)
```

Select only the columns you're interested in:
```{r}
df_meta = df %>% select(`Authors`, `Sample size included`, `Sex (%female)`, `Ethnic background (% white)`,
                        `age range`, `d or R`, `effect size`, `V`, `95% CI`)
```

Change the names of the columns:
```{r}
transform_var_names <- function(df) {
  # transform the columns names with space into _ 
  var_names <- names(df)
  new_var_names <- gsub(" ", "_", var_names)
  names(df) <- new_var_names
  # Return the modified data frame
  return(df)
}

# Use the function
df_meta = transform_var_names(df_meta)
colnames(df_meta)
```

Select only the effect size available (r or d)
```{r}
df_meta = df_meta[df_meta$d_or_R == "r" | df_meta$d_or_R == "d", ]
df_meta$d_or_R = as.factor(df_meta$d_or_R)
```

Remove all the rows that present a NA value inside the variance variable
```{r}
df_meta = df_meta[!is.na(df_meta$V),]
```

Convert the percentages into prevalence value between 0 and 1:
```{r}
convert_percentage <- function(vec) {
  percentage_indices <- grepl("%$", vec)
  vec[percentage_indices] <- as.numeric(sub("%", "", vec[percentage_indices])) / 100
  vec = as.numeric(vec)
  return(vec)
}
```

For the varibles ethnic and female, convert some variables from "-" to NA and then convert all the percentages variables
```{r}
df_meta$`Ethnic_background_(%_white)` = ifelse(df_meta$`Ethnic_background_(%_white)` == "-", NA, df_meta$`Ethnic_background_(%_white)`)
df_meta$`Ethnic_background_(%_white)` = convert_percentage(df_meta$`Ethnic_background_(%_white)`)


df_meta$`Sex_(%female)` = ifelse(df_meta$`Sex_(%female)` == '-', NA, df_meta$`Sex_(%female)`)
df_meta$`Sex_(%female)` = convert_percentage(df_meta$`Sex_(%female)`)
```

Checking if Sex is numeric:
```{r}
is.numeric(df_meta$`Sex_(%female)`)
```

Converting the wrong value of effect size (we can see that the correct has the point from the confidence interval)
```{r}
print(df_meta$effect_size[30])
df_meta$effect_size[30] = '1.177'
df_meta$effect_size[30]
```

```{r}
# Define the function
convert_values <- function(vec) {
  # Identify the elements that end with a "%" sign
  percentage_indices <- grepl("%$", vec)
  
  # For these elements, remove the "%" sign, convert to numeric, and divide by 100
  vec[percentage_indices] <- as.numeric(sub("%", "", vec[percentage_indices])) / 100
  
  # Identify the elements that start with "("
  bracket_indices <- grepl("^\\(", vec)
  
  # For these elements, remove the "(" and ")" characters and convert to numeric
  vec[bracket_indices] <- as.numeric(sub("\\)$", "", sub("^\\(", "", vec[bracket_indices])))
  
  # Convert the rest of the vector to numeric
  vec[!is.na(vec) & !percentage_indices & !bracket_indices] <- as.numeric(vec[!is.na(vec) & !percentage_indices & !bracket_indices])
  
  # Return the modified vector
  return(vec)
}


df_meta$effect_size = convert_values(df_meta$effect_size)
```

```{r}
df_meta$V = as.numeric(df_meta$V)
df_meta$effect_size = as.numeric(df_meta$effect_size)
df_meta$SE = sqrt(df_meta$V)
```

```{r}
str(df_meta)
```

### handling the CI 

Convert the CI that present 3 commas (error) into only 1 (the second)
```{r}
library(stringr)
num_commas = str_count(df_meta$`95%_CI`, ',')
ind = which(num_commas == 3)

for(i in ind) {
  string = df_meta$`95%_CI`[i]
  string = gsub("^\\[([^,]*),", "[\\1.", string)
  string = gsub(",([^,]*)\\]$", ".\\1]", string)
  df_meta$`95%_CI`[i] = string 
}
df_meta$`95%_CI`
```
Define a function to separate the two values of the confidence interval:
```{r}
# Define the function
split_values <- function(vec) {
  # Split the string at the comma
  split_vec <- strsplit(vec, ",")
  
  # Initialize vectors for val1 and val2
  val1 <- numeric(length(vec))
  val2 <- numeric(length(vec))
  
  # Loop over the split_vec list
  for (i in seq_along(split_vec)) {
    # Check if there are more than two elements
    if (length(split_vec[[i]]) > 2) {
      # There is an error
      next
    }
    
    # Remove the "[" and "]" characters, replace any commas with periods, and convert to numeric
    val1[i] <- as.numeric(sub(",", ".", gsub("\\[", "", split_vec[[i]][1])))
    val2[i] <- as.numeric(sub(",", ".", gsub("\\]", "", split_vec[[i]][2])))
  }
  
  # Return a data frame with two columns
  return(data.frame(lower_CI = val1, upper_CI = val2))
}

# Use the function
df = split_values(df_meta$`95%_CI`)
df
```

```{r}
df_meta$lower_CI = df$lower_CI
df_meta$upper_CI = df$upper_CI
```

Using the formula for calculating the SE from the CI, but
```{r}
# this is wrong!!
#df_meta$SE = (df_meta$effect_size - df_meta$lower_CI)/qnorm(0.975)
```

Using the formula for calculating the SE from the CI for both lower and upper values: 
```{r}
(df_meta$effect_size - df_meta$lower_CI)/qnorm(0.975)
```

```{r}
(df_meta$upper_CI - df_meta$effect_size)/(qnorm(0.975))
```
Comparing it to the standard deviation of the estimate is identicale: therefore you used the sd for calculating the CI, but this is indeed wrong! 
```{r}
sqrt(df_meta$V) # standard deviation (square root of the standar error)
```

```{r}
df_meta$SE
```

## Converting the r measurements into d measurements

```{r}
str(df_meta)
```


Converting r to d, standardize and perform the analysis

```{r}
convert_r_to_d = function(r){
  num = 2*r
  denom = sqrt((1 - r^2))
  return(num/denom)
}

convertSE_r_toSE_d = function(SE, r){
  num = 4*sqrt(SE)
  denom = (1 - r^2)^3
  return(sqrt(num/denom))
}
```

```{r}
df_meta_r = df_meta[df_meta$d_or_R == "r", ]
```

```{r}
colnames(df_meta_r)
```


```{r}
df_meta_r |> select(effect_size, SE)
```



```{r}
# Apply the functions only to the rows where d_or_R is 'r'
df_meta_r$effect_size_d = convert_r_to_d(df_meta_r$effect_size)

# standard deviation sqrt(V) = SE

# This SE is wrong!!!!
df_meta_r$SE = convertSE_r_toSE_d(df_meta_r$SE, df_meta_r$effect_size)
```

```{r}
df_meta_r |> select(effect_size_d, SE)
```



```{r}
ind = which(df_meta$d_or_R == "r")
df_meta$effect_size[ind] = df_meta_r$effect_size_d
df_meta$SE[ind] = df_meta_r$SE
```
Now all our effect sizes are d!


```{r}
df_meta$effect_size
```

```{r}
df_meta$SE
```


```{r}
# Find the maximum value in the SE column
max_se_value <- max(df_meta$SE)

# Remove rows with the maximum SE value
df_meta <- df_meta[df_meta$SE != max_se_value, ]

```

```{r}
dim(df_meta)
```

```{r}
col_names = colnames(df_meta)
col_names[2] = "N"
col_names[3] = "female_prevalence"
col_names[4] = "white_prevalence"
col_names[6] = "type"
colnames(df_meta) = col_names
colnames(df_meta)
```


Converting our effect sizes into the SMD, need to check that this is indeed true

```{r}
names(df_meta)
```


```{r}
first_names = sapply(strsplit(df_meta$Authors, ", "), function(x) x[1])
full_names = paste(first_names, "et al.", sep = ", ")
df_meta$Authors = full_names
df_meta$Authors[11] = "Dal Bo, et al."
df_meta$Authors[39] = "Mohammadi, et al."
```

```{r}
df_meta$Authors
```



```{r}
# Compute the standardized mean difference and its variance
df_meta = escalc(measure = "SMD", n1i = N, n2i = N,
                 yi = effect_size, sei = SE, slab = Authors, 
                 data = df_meta)
```

```{r}
df_meta$V
```


```{r}
df_meta$vi # notice that the variances have been changed only for the r measures
```



```{r}
(ran <- rma(yi, vi, data=df_meta, method="DL"))
```

```{r}
funnel(ran)                   # funnel plot with default settings, can be made prettier, see ?funnel
forest(ran) 
```
```{r}
inf = influence(ran)
inf$inf$inf
```


## Multilevel model

```{r}
(multi_ran <- rma.mv(yi, vi, random = list(~ 1 | Authors),
                  tdist = TRUE, data=df_meta))
```

```{r}
par(mar=c(4,4,2,2))
forest(multi_ran, header = T, mlab = "Summary",
       cex = 0.5)
```
```{r}
funnel(multi_ran)
```








