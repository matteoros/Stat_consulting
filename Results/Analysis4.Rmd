---
title: "example_multilevel"
author: "Matteo Rossi"
date: "2023-12-01"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Set up file

```{r}
##### Clear global environment and console
rm(list = ls()) #GE
cat("\014") # console

##### Load libraries
library(readxl) 
library(dplyr) 
library(metafor) # package used for meta-analyses
library(ggplot2)
```
## Reading and cleaning the data, check out measure distribution

```{r}
##### Read in papers
df = read_excel("PaperCharacterizationTable_Meta_RA.xlsx", sheet = "Metacognition", skip = 1)
df = df %>% select(-starts_with('...'))
head(df)

freq = table(df$"Authors")
df_table <- as.data.frame(table(as.data.frame(freq)[,2]))


##### Measure distribution before we remove anything
p <- ggplot(data = df_table, aes(x = Var1, y = Freq)) +
  geom_bar(stat = "identity", color = 'steelblue2', fill = 'steelblue2') +
  theme_bw() +
  theme(panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank()) +
  scale_y_continuous(breaks = seq(0, max(df_table$Freq), by = 2)) +
  labs(x = "# of Metacognition Measures Assessed Per Study", 
       y = "# of Studies Using the Different Amounts of Measures", 
       title = "# of Studies Using the Different Amounts of Metacognition Measures")

p
rm(freq, df_table)
```
### Select only the columns we're interested in:
```{r}
##### Preallocate the dataframe, and rename the columns in 
df_meta = data.frame(matrix(ncol = 13, nrow = nrow(df))) # preallocate the dataframe

colnames(df_meta) = c('Authors', 
                      'Year', # Year of publication 
                      'Age', # Mean age
                      'Clinical', # Clinical vs. recruited participants
                      'Instrument', #  metacognition instrument, e.g. MCQ-C
                      'Instrument_simpl',
                      'Dimensions', # metacognition dimension, e.g. positive beliefs 
                      'Summary_dim', # preallocate for later when we summarize metacognition dims. 
                      'N', # Sample size included (of SAD patients)
                      'd_r', # effect measure type
                      'effect_size', 
                      'V', # variance
                      '95_CI') # 95% confidence interval

##### Select only those relevant columns from the original dataframe
df_meta[,colnames(df_meta)] = df %>% select(`Authors`, `Year of publication`,
                                              `mean age`, `Clinical sample`, `Metacognition trait or state`, `Manipulation`,# moderators
                                              `Dimensions used (if looked at different dimension make separate rows for each dimension)`,
                                              `Origin Country of study`, # intentionally included. will be excluded later
                                              `Sample size included`, `d or R`, `effect size`, `V`, `95% CI`)

df_meta$Dimensions[df_meta$Dimensions == "postive dimension"] = "positive dimension"
##### Indicate which measures are general (are not specifically positive or negative)
df_meta$Summary_dim = df_meta$Dimensions
meta_measure = which(!(df_meta$Summary_dim %in% c("positive dimension", "negative dimension"))) 
df_meta$Summary_dim[meta_measure] = "General"

##### Summarize MCQ measures (since ultimately they're rephrased for children, but they ask the same questions)
df_meta$Instrument_simpl = df_meta$Instrument
df_meta$Instrument_simpl[grep("MCQ", df_meta$Instrument)] <- "MCQ"

rm(meta_measure)
df_meta |> select(Dimensions, Summary_dim)
```

### Clean up paper titles
```{r Author formatting}
##### Two papers have missing commas after the surname
df_meta$Authors[df_meta$Authors == "Dal Bo E. and Gentili C. and Fischmeister F.Ph.S. and Cecchetto C."] = "Dal Bo, E. and Gentili, C. and Fischmeister, F.Ph.S. and Cecchetto, C."
df_meta$Authors[df_meta$Authors == "Mohammadi B. and Beige N.A."] <- "Mohammadi, B. and Beige, N.A."


##### Rename the authors so that the names are abbreviated, and so that each paper has a unique name ID
first_names = sapply(strsplit(df_meta$Authors, ", "), function(x) x[1])
full_names = paste(first_names, "et al.", df_meta$Year, sep = ", ")
df_meta$Authors = full_names


##### Add in A and B to the unique studies with the same authors and year of publication
Hearn = which(df_meta$Authors == "Hearn, et al., 2017")
df_meta$Authors[Hearn[1:2]] = paste(df_meta$Authors[Hearn[1]], "A")
df_meta$Authors[Hearn[3:4]] = paste(df_meta$Authors[Hearn[3]], "B")


##### We define a function so that you can see how many papers remain after removing those with missing information.
papers_left = function(df){sprintf("%.2f papers",length(unique(df_meta$Authors)))} # I changed here df_meta instead of df
papers_left(df_meta) # We start with 26

##### Remove unused variables
rm(first_names, full_names, Hearn)
```

### Standardize all of the input types 
```{r}
##### remove the parentheses from the effect sizes and correct typo (we can see where the decimal goes from the confidence interval)
df_meta$effect_size <- gsub("[()]", "", df_meta$effect_size) # remove ()
typo = which(df_meta$effect_size==1177)
df_meta$effect_size[typo] = 1.177 # correct typo


##### Standardize type per column
# Numeric variables
numeric_columns <- c('Age', 'N', 'effect_size', 'V')
df_meta[, numeric_columns] <- lapply(df_meta[, numeric_columns], as.numeric) # this is giving the warning that is introducing NAs

# Factor variables
factor_columns <- c('Authors', 'Clinical', 'Instrument', 'Instrument_simpl', 'Dimensions', 'Summary_dim', 'd_r')
df_meta[, factor_columns] <- lapply(df_meta[, factor_columns], as.factor)
df_meta$Instrument[df_meta$Instrument == "-"] = NA

rm(numeric_columns,factor_columns, typo) 
```


### Compute standard Error and standardize confidence interval reporting

It is also possible to calculat the confidence interval directly from the estimate and the sd (for effect sizes SE = sd).
```{r}
##### Add in standard error column
df_meta$SE = sqrt(df_meta$V)


##### Standardize confidence intervals. Some entries use comma separator, some use period. We standardize to use a period.
library(stringr)
num_commas = str_count(df_meta$`95_CI`, ',')
ind = which(num_commas == 3)

for(i in ind) {
  string = df_meta$`95_CI`[i]
  string = gsub("^\\[([^,]*),", "[\\1.", string)
  string = gsub(",([^,]*)\\]$", ".\\1]", string)
  df_meta$`95_CI`[i] = string 
}

##### Define function for splitting the confidence intervals into two separate columns so that they can be encoded as numeric
split_values <- function(vec) {
  # Split the string at the comma
  split_vec <- strsplit(vec, ",")
  
  # Initialize vectors for val1 and val2
  val1 <- numeric(length(vec))
  val2 <- numeric(length(vec))
  
  # Loop over the split_vec list
  for (i in seq_along(split_vec)) {
    # Check if there are more than two elements
    if (length(split_vec[[i]]) > 2) {
      # There is an error
      next
    }
    
    # Remove the "[" and "]" characters, replace any commas with periods, and convert to numeric
    val1[i] <- as.numeric(sub(",", ".", gsub("\\[", "", split_vec[[i]][1])))
    val2[i] <- as.numeric(sub(",", ".", gsub("\\]", "", split_vec[[i]][2])))
  }
  
  # Return a data frame with two columns
  return(data.frame(lower_CI = val1, upper_CI = val2))
}

##### Employ function on the data set. lower_CI becomes the lower bound, and upper_CI becomes the upper bound
df = split_values(df_meta$'95_CI') # this is introducing NAs
df_meta[ , c("lower_CI","upper_CI")] = df
df_meta <- df_meta %>% select(-"95_CI") # remove the original variable

rm(i, ind, num_commas, string, df)
df_meta
```
### Remove studies with missing information
Select only if the effect size is available (r or d)
```{r}
##### Find papers which do not have an r or a d measure
no_d_r = which(!(df_meta$d_r %in% c("r", "d"))) 
df_meta[no_d_r,] |> nrow()

##### Find papers which do not have a variance
no_var = which(is.na(df_meta$V))
df_meta[no_var,] |> nrow()

##### Find papers which do not have a mean age
no_age = which(is.na(df_meta$Age))
df_meta[no_age,] |> nrow()

##### Some may have two measures missing, so we want the unique rows to remove:
row_rm = unique(c(no_d_r, # no d or r measure
                  no_var, # no variance
                  no_age))# no median age
length(row_rm)

##### Remove the papers with missing information 
df_meta = df_meta[-row_rm,]
papers_left(df_meta) #number of papers left 

rm(no_age, no_d_r, no_var, row_rm)
df_meta


##### Measure distribution after problematic papers removed
freq = table(df_meta$"Authors")
df_table <- as.data.frame(table(as.data.frame(freq)[,2]))

p1 <- ggplot(data = df_table, aes(x = Var1, y = Freq)) +
  geom_bar(stat = "identity", color = 'steelblue', fill = 'steelblue') +
  theme_bw() +
  theme(panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank()) +
  scale_y_continuous(breaks = seq(0, max(df_table$Freq), by = 2)) +
  labs(x = "# of Metacognition Measures Assessed Per Study", 
       y = "# of Studies Using the Different Amounts of Measures", 
       title = "# of Studies Using the Different Amounts of Metacognition Measures")

p1
rm(freq,df_table)
```

## Considering only r effect sizes

```{r}
df_meta_r = df_meta[df_meta$d_r == "r", ]
```

```{r}
df_meta_r = escalc(measure = "ZCOR", ri = effect_size, ni = N,
                   data = df_meta_r, slab = Authors)
```

### Multilevel Model

Adding the unique identifier for each estimate
```{r}
df_meta_r$es.id = 1:nrow(df_meta_r)
```

```{r}
colnames(df_meta_r)
```


```{r}
multi_result <- rma.mv(yi = yi, 
                     V = vi, 
                     slab = Authors,
                     data = df_meta_r,
                     random = ~ 1 | Authors/es.id, 
                     test = "t", 
                     method = "REML")
```

```{r}
summary(multi_result)
```

```{r}
library(esc)
convert_z2r(0.3059)
```
This is the resulting correlation estimated in the population

```{r}
calculate_estimates <- function(result_r1) {
  # Calculate W
  W <- diag(1/result_r1$vi)
  
  # Calculate X
  X <- model.matrix(result_r1)
  
  # Calculate P
  P <- W - W %*% X %*% solve(t(X) %*% W %*% X) %*% t(X) %*% W
  
  # Calculate I_square
  I_square = 100 * sum(result_r1$sigma2) / (sum(result_r1$sigma2) + (result_r1$k-result_r1$p)/sum(diag(P)))
  
  # Calculate Separated_I_squared
  Separated_I_squared = 100 * result_r1$sigma2 / (sum(result_r1$sigma2) + (result_r1$k-result_r1$p)/sum(diag(P)))
  
  # Name the elements of Separated_I_squared
  names(Separated_I_squared) = c("between_variance", "within_variance")
  
  # Calculate remaining_sampling_variance
  remaining_sampling_variance = 100 - sum(Separated_I_squared)
  
  # Return the results as a list
  return(list(I_square = I_square, Separated_I_squared = Separated_I_squared, remaining_sampling_variance = remaining_sampling_variance))
}

```

```{r}
calculate_estimates(multi_result)
```




```{r}
library(dmetar)
i2 <- var.comp(multi_result)
summary(i2)
```


```{r}

removed <- rma.mv(yi = yi, 
                     V = vi, 
                     slab = Authors,
                     data = df_meta_r,
                     random = ~ 1 | Authors/es.id, 
                     test = "t", 
                     method = "REML",
                     sigma2 =  c(0, NA))
```

```{r}
summary(removed)
```

```{r}
anova(multi_result, removed)
```

There is stastically significance in the difference!

```{r}
moder1 =  rma.mv(yi = yi, 
                     V = vi, 
                     slab = Authors,
                     data = df_meta_r,
                     random = ~ 1 | Authors/es.id, 
                     test = "t", 
                     method = "REML",
                 mods = ~ Age)
```

```{r}
summary(moder1)
```




