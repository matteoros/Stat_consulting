---
title: "example_multilevel"
author: "Matteo Rossi"
date: "2023-12-01"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Set up file

```{r}
##### Clear global environment and console
rm(list = ls()) #GE
cat("\014") # console

##### Load libraries
library(readxl) 
library(dplyr) 
library(metafor) # package used for meta-analyses
library(ggplot2)
```
## Reading and cleaning the data, check out measure distribution

```{r}
##### Read in papers
df = read_excel("PaperCharacterizationTable_Meta_RA.xlsx", sheet = "Metacognition", skip = 1)
df = df %>% select(-starts_with('...'))
head(df)

freq = table(df$"Authors")
df_table <- as.data.frame(table(as.data.frame(freq)[,2]))


##### Measure distribution before we remove anything
p <- ggplot(data = df_table, aes(x = Var1, y = Freq)) +
  geom_bar(stat = "identity", color = 'steelblue2', fill = 'steelblue2') +
  theme_bw() +
  theme(panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank()) +
  scale_y_continuous(breaks = seq(0, max(df_table$Freq), by = 2)) +
  labs(x = "# of Metacognition Measures Assessed Per Study", 
       y = "# of Studies Using the Different Amounts of Measures", 
       title = "# of Studies Using the Different Amounts of Metacognition Measures")

p
rm(freq, df_table)
```


### Select only the columns we're interested in:
```{r}
##### Preallocate the dataframe, and rename the columns in 
df_meta = data.frame(matrix(ncol = 13, nrow = nrow(df))) # preallocate the dataframe

colnames(df_meta) = c('Authors', 
                      'Year', # Year of publication 
                      'Age', # Mean age
                      'Clinical', # Clinical vs. recruited participants
                      'Instrument', #  metacognition instrument, e.g. MCQ-C
                      'Instrument_simpl',
                      'Dimensions', # metacognition dimension, e.g. positive beliefs 
                      'Summary_dim', # preallocate for later when we summarize metacognition dims. 
                      'N', # Sample size included (of SAD patients)
                      'd_r', # effect measure type
                      'effect_size', 
                      'V', # variance
                      '95_CI') # 95% confidence interval

##### Select only those relevant columns from the original dataframe
df_meta[,colnames(df_meta)] = df %>% select(`Authors`, `Year of publication`,
                                              `mean age`, `Clinical sample`, `Metacognition trait or state`, `Manipulation`,# moderators
                                              `Dimensions used (if looked at different dimension make separate rows for each dimension)`,
                                              `Origin Country of study`, # intentionally included. will be excluded later
                                              `Sample size included`, `d or R`, `effect size`, `V`, `95% CI`)

df_meta$Dimensions[df_meta$Dimensions == "postive dimension"] = "positive dimension" # fix typo


##### Indicate which measures are general (are not specifically positive or negative)
df_meta$Summary_dim = df_meta$Dimensions
meta_measure = which(!(df_meta$Summary_dim %in% c("positive dimension", "negative dimension"))) 
df_meta$Summary_dim[meta_measure] = "general dimension"

##### Summarize MCQ measures (since ultimately they're rephrased for children, but they ask the same questions)
df_meta$Instrument_simpl = df_meta$Instrument
df_meta$Instrument_simpl[grep("MCQ", df_meta$Instrument)] <- "MCQ"

rm(meta_measure, freq)
df_meta |> select(Dimensions, Summary_dim)
```

### Clean up paper titles
```{r Author formatting}
##### Two papers have missing commas after the surname
df_meta$Authors[df_meta$Authors == "Dal Bo E. and Gentili C. and Fischmeister F.Ph.S. and Cecchetto C."] = "Dal Bo, E. and Gentili, C. and Fischmeister, F.Ph.S. and Cecchetto, C."
df_meta$Authors[df_meta$Authors == "Mohammadi B. and Beige N.A."] <- "Mohammadi, B. and Beige, N.A."


##### Rename the authors so that the names are abbreviated, and so that each paper has a unique name ID
first_names = sapply(strsplit(df_meta$Authors, ", "), function(x) x[1])
full_names = paste(first_names, "et al.", df_meta$Year, sep = ", ")
df_meta$Authors = full_names


##### Add in A and B to the unique studies with the same authors and year of publication
Hearn = which(df_meta$Authors == "Hearn, et al., 2017")
df_meta$Authors[Hearn[1:2]] = paste(df_meta$Authors[Hearn[1]], "A")
df_meta$Authors[Hearn[3:4]] = paste(df_meta$Authors[Hearn[3]], "B")


##### Add in title of questionnaire from study
df_meta[df_meta$Authors == "Modini, et al., 2018","Instrument_simpl"] = "Thoughts Questionnaire (negative rumination subscale)"
##### We define a function so that you can see how many papers remain after removing those with missing information.
papers_left = function(df){sprintf("%.2f papers",length(unique(df_meta$Authors)))} # I changed here df_meta instead of df
papers_left(df_meta) # We start with 26

##### Remove unused variables
rm(first_names, full_names, Hearn)
```

### Standardize all of the input types 
```{r}
##### remove the parentheses from the effect sizes and correct typo (we can see where the decimal goes from the confidence interval)
df_meta$effect_size <- gsub("[()]", "", df_meta$effect_size) # remove ()
typo = which(df_meta$effect_size==1177)
df_meta$effect_size[typo] = 1.177 # correct typo


##### Standardize type per column
# Numeric variables
numeric_columns <- c('Age', 'N', 'effect_size', 'V')
df_meta[, numeric_columns] <- lapply(df_meta[, numeric_columns], as.numeric) # this is giving the warning that is introducing NAs

# Factor variables
factor_columns <- c('Authors', 'Clinical', 'Instrument', 'Instrument_simpl', 'Dimensions', 'Summary_dim', 'd_r')
df_meta[, factor_columns] <- lapply(df_meta[, factor_columns], as.factor)
df_meta$Instrument[df_meta$Instrument == "-"] = NA

rm(numeric_columns,factor_columns, typo) 
```


### Compute standard Error and standardize confidence interval reporting

It is also possible to calculat the confidence interval directly from the estimate and the sd (for effect sizes SE = sd).
```{r}
##### Add in standard error column
df_meta$SE = sqrt(df_meta$V)


##### Standardize confidence intervals. Some entries use comma separator, some use period. We standardize to use a period.
library(stringr)
num_commas = str_count(df_meta$`95_CI`, ',')
ind = which(num_commas == 3)

for(i in ind) {
  string = df_meta$`95_CI`[i]
  string = gsub("^\\[([^,]*),", "[\\1.", string)
  string = gsub(",([^,]*)\\]$", ".\\1]", string)
  df_meta$`95_CI`[i] = string 
}

##### Define function for splitting the confidence intervals into two separate columns so that they can be encoded as numeric
split_values <- function(vec) {
  # Split the string at the comma
  split_vec <- strsplit(vec, ",")
  
  # Initialize vectors for val1 and val2
  val1 <- numeric(length(vec))
  val2 <- numeric(length(vec))
  
  # Loop over the split_vec list
  for (i in seq_along(split_vec)) {
    # Check if there are more than two elements
    if (length(split_vec[[i]]) > 2) {
      # There is an error
      next
    }
    
    # Remove the "[" and "]" characters, replace any commas with periods, and convert to numeric
    val1[i] <- as.numeric(sub(",", ".", gsub("\\[", "", split_vec[[i]][1])))
    val2[i] <- as.numeric(sub(",", ".", gsub("\\]", "", split_vec[[i]][2])))
  }
  
  # Return a data frame with two columns
  return(data.frame(lower_CI = val1, upper_CI = val2))
}

##### Employ function on the data set. lower_CI becomes the lower bound, and upper_CI becomes the upper bound
df = split_values(df_meta$'95_CI') # this is introducing NAs
df_meta[ , c("lower_CI","upper_CI")] = df
df_meta <- df_meta %>% select(-"95_CI") # remove the original variable

rm(i, ind, num_commas, string, df)
df_meta
```
### Remove studies with missing information
Select only if the effect size is available (r or d)
```{r}
##### Find papers which do not have an r or a d measure
no_d_r = which(!(df_meta$d_r %in% c("r", "d"))) 
df_meta[no_d_r,] |> nrow()

##### Find papers which do not have a variance
no_var = which(is.na(df_meta$V))
df_meta[no_var,] |> nrow()

##### Find papers which do not have a mean age
no_age = which(is.na(df_meta$Age))
df_meta[no_age,] |> nrow()

##### Some may have two measures missing, so we want the unique rows to remove:
row_rm = unique(c(no_d_r, # no d or r measure
                  no_var, # no variance
                  no_age))# no median age
length(row_rm)

##### Remove the papers with missing information 
df_meta = df_meta[-row_rm,]
papers_left(df_meta) #number of papers left 

rm(no_age, no_d_r, no_var, row_rm)
df_meta

```

```{r}
library(ggpubr) 
##### prep dataframe for barplots. 

# Some studies which have since been removed, and they show up with 0 effect measures
df_meta$Authors <- as.character(df_meta$Authors)
unique_authors <- unique(df_meta$Authors)
df_meta$Authors <- factor(df_meta$Authors, levels = unique_authors)

# Some studies have since been removed, and they show up with 0 dimensions
df_meta$Dimensions <- as.character(df_meta$Dimensions)
unique_dimensions <- unique(df_meta$Dimensions)
df_meta$Dimensions <- factor(df_meta$Dimensions, levels = unique_dimensions)


##### Studies that use given numbers of measures
freq = table(df_meta$"Authors")
df_table <- as.data.frame(table(as.data.frame(freq)[,2]))

p1 <- ggplot(data = df_table, aes(x = Var1, y = Freq)) +
  geom_bar(stat = "identity", color = 'gray', fill = 'gray') +
  theme_bw() +
  theme(panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank()) +
  scale_y_continuous(breaks = seq(0, max(df_table$Freq), by = 2)) +
  labs(x = "# of Measures per study",
       y = "# of Studies Using Measure Amount",
       title = "Full Dimensions")
p1


##### How many studies use a given measure with the full dimensions
freq = as.data.frame(table(df_meta$Dimensions))
p2 <- ggplot(data = freq, mapping = aes(x = reorder(Var1, Freq), Freq)) +
  geom_bar(stat = "identity", color = 'steelblue2', fill = 'steelblue2') +
  theme_bw() +
  theme(panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank(),
        axis.text.x = element_text(angle = 55, hjust=1)) +
  scale_y_continuous(breaks = seq(0, max(freq$Freq), by = 2)) +
  labs(title = "Full Dimensions",
       x = "Measure Identity",
       y = "# Of Studies Using a Given Measure")
p2

##### How many studies use a given measure with the summary dimensions
freq = as.data.frame(table(df_meta$Summary_dim))
p3 <- ggplot(data = freq, mapping = aes(x = reorder(Var1, Freq), Freq)) +
  geom_bar(stat = "identity", color = 'steelblue2', fill = 'steelblue2') +
  theme_bw() +
  theme(panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank(),
        axis.text.x = element_text(angle = 55, hjust=1)) +
  scale_y_continuous(breaks = seq(0, max(freq$Freq), by = 2)) +
  labs(title = "Summary Dimensions",
       x = "Measure Identity",
       y = "Occurence of Measure Across Studies")
p3

##### Display them all together
figure = ggarrange(p1, p2, p3,
          labels = c("A", "B", "C"),
          ncol = 3, nrow = 1, align = "h")
figure
```
```{r}
inst = table(unique(df_meta[,c("Clinical","Authors")])$Clinical)
freq =  as.data.frame(inst[inst != 0])
p4 <- ggplot(data = freq, mapping = aes(x = reorder(Var1, Freq), Freq)) +
  geom_bar(stat = "identity", color = 'steelblue2', fill = 'steelblue2') +
  theme_bw() +
  theme(panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank(),
        axis.text.x = element_text(angle = 55, hjust=1)) +
  scale_x_discrete(labels = c("Clinical +","Clinical -")) + 
  scale_y_continuous(breaks = seq(0, max(freq$Freq), by = 2)) +
  labs(title = "Study Population",
       x = "Clinical Level",
       y = "# Of Studies With Pop. Level")
p4


inst = table(unique(df_meta[,c("Instrument_simpl","Authors")])$Instrument_simpl)
freq =  as.data.frame(inst[inst != 0])

p5 <- ggplot(data = freq, mapping = aes(x = reorder(Var1, Freq), Freq)) +
  geom_bar(stat = "identity", color = 'steelblue2', fill = 'steelblue2') +
  theme_bw() +
  theme(panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank(),
        axis.text.x = element_text(angle = 55, hjust=1)) +
  scale_x_discrete(labels = c("VAS-S", " BLC-I", "MW-Q", "PEP-Q", "PBR-S", "SO-S", "T-Q", "MC-Q")) + 
  scale_y_continuous(breaks = seq(0, max(freq$Freq), by = 2)) +
  labs(title = "Metacog. Meas. Inst.",
       x = "Metacog. Instrument Identity",
       y = "# Of Studies Using a Given Instrument")
p5

p6 <- ggplot(data = df_meta[,c("Age","Authors")], mapping = aes(x = reorder(Authors, Age), Age)) + geom_point() +
  theme_bw() +
  theme(panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank(),
        axis.text.x = element_text(angle = 90, hjust=1)) +
  scale_x_discrete() + 
  scale_y_continuous(breaks = seq(0, max(df_meta$Age), by = 2)) +
  labs(title = "Mean Age per Study",
       x = "Study",
       y = "Mean Participant Age")
p6
figure = ggarrange(p6, p5, p4,
          labels = c("A", "B", "C"),
          ncol = 3, nrow = 1, align = "h")

figure
```


## Considering all the measures in this dataframe

Converting d into r measures

```{r}
library(esc) # importing the package to use convert_d2r

# use only the data that present a d measurement
d_mes = df_meta[df_meta$d_r == "d", ]

r_values = list()
for(i in 1:nrow(d_mes)){
  r_values[[i]] = convert_d2r(d = d_mes$effect_size[i], v = d_mes$V[i],
                            grp1n = d_mes$N[i] , grp2n = d_mes$N[i])
}

# save only the effect sizes and variances:
r_es = numeric(10)
r_V = numeric(10)
for(i in 1:10){
  r_es[i] = r_values[[i]]$es
  r_V[i] = r_values[[i]]$var
}

# put the results into the original dataframe
df_meta$effect_size[df_meta$d_r == "d"] = r_es
df_meta$V[df_meta$d_r == "d"] = r_V
df_meta$d_r = "r"
```


Function for calculating the between and within I^2:

```{r}
calculate_estimates <- function(result_r1) {
  # Calculate W
  W <- diag(1/result_r1$vi)
  
  # Calculate X
  X <- model.matrix(result_r1)
  
  # Calculate P
  P <- W - W %*% X %*% solve(t(X) %*% W %*% X) %*% t(X) %*% W
  
  # Calculate I_square
  I_square = 100 * sum(result_r1$sigma2) / (sum(result_r1$sigma2) + (result_r1$k-result_r1$p)/sum(diag(P)))
  
  # Calculate Separated_I_squared
  Separated_I_squared = 100 * result_r1$sigma2 / (sum(result_r1$sigma2) + (result_r1$k-result_r1$p)/sum(diag(P)))
  
  # Name the elements of Separated_I_squared
  names(Separated_I_squared) = c("between_variance", "within_variance")
  
  # Calculate remaining_sampling_variance
  remaining_sampling_variance = 100 - sum(Separated_I_squared)
  
  # Return the results as a list
  return(list('Total I^2' = I_square, Separated_I_squared = Separated_I_squared, remaining_sampling_variance = remaining_sampling_variance))
}

```

### replication of the analysis performed

```{r}
# obtaining Z correlations from the r correlations
df_meta = escalc(measure = "ZCOR", ri = effect_size, ni = N,
                   data = df_meta, slab = Authors)

df_meta$es.id = paste0("id_", 1:nrow(df_meta)) # differentiating between the different effect sizes
```

```{r}
# fitting the three levels model
multi_result <- rma.mv(yi = yi, 
                     V = vi, 
                     slab = Authors,
                     data = df_meta,
                     random = ~ 1 | Authors/es.id, 
                     test = "t", 
                     method = "REML")
```

```{r}
summary(multi_result)
```
```{r}
calculate_estimates(multi_result)
```

```{r}
convert_z2r(0.2625)
```

```{r}
forest(multi_result, header = T, mlab = "Summary", cex = 0.5)
```


### Moderator analysis on the full dataset

Model 1: Including Age and Clinical as moderators
```{r}
mod1 <- rma.mv(yi = yi, 
                     V = vi, 
                     slab = Authors,
                     data = df_meta,
                     random = ~ 1 | Authors/es.id, 
                     test = "t", 
                     mods = ~ Age + Clinical,
                     method = "REML")
```

```{r}
summary(mod1)
```
Considering the test of moderators, we notice that is not significant (p_val $= 0.3158$, so we cannot reject the null hypothesis). Therefore it is necessary to remove such moderators from the analysis.

```{r}
anova(mod1, multi_result, refit=TRUE)
```
We notice that the model without moderators present the lowest value of AIC therefore is preferable. Moreover we notice that even if there is no statistical difference between the two models, based on Occam's razor we should prefer the simplest model (without moderators). It also possible to notice that each p value of each moderator included is not significant. 

```{r}
mod2 <- rma.mv(yi = yi,
               V = vi, 
               slab = Authors,
               data = df_meta,
               random = ~ 1 | Authors/es.id, 
               test = "t", 
               mods = ~ Summary_dim,
               method = "REML")
```

```{r}
summary(mod2)
```
Only the General Dimension is significant.

```{r}
mod3 <- rma.mv(yi = yi,
               V = vi, 
               slab = Authors,
               data = df_meta,
               random = ~ 1 | Authors/es.id, 
               test = "t", 
               mods = ~ Dimensions,
               method = "REML")
summary(mod3)
```


```{r}
mod0 <- rma.mv(yi = yi, 
                     V = vi, 
                     slab = Authors,
                     data = df_meta,
                     random = ~ 1 | Authors/es.id, 
                     test = "t", 
                     method = "REML",
                     sigma2 =  c(0, NA))
summary(mod0)
convert_z2r(summary(mod0)$b)
mod0ests = calculate_estimates(mod0)
mod0ests$Separated_I_squared/mod0ests$`Total I^2`

##################
mod1 <- rma.mv(yi = yi, 
                     V = vi, 
                     slab = Authors,
                     data = df_meta,
                     random = ~ 1 | Authors/es.id, # Random effect/metacognition measure 
                     test = "t",
                     method = "REML")
summary(mod1)
convert_z2r(summary(mod1)$b)
calculate_estimates(mod1)

anova(mod1, mod0)
forest(mod1, header = T, mlab = "Summary", cex = 0.5)

##################
mod2 <- rma.mv(yi = yi, 
                     V = vi, 
                     slab = Authors,
                     data = df_meta,
                     random = ~ 1 | Authors/es.id, 
                     test = "t", 
                     mods = ~ Age,
                     method = "REML")
summary(mod2)
convert_z2r(summary(mod2)$b)
calculate_estimates(mod2)


##################
mod3 <- rma.mv(yi = yi, 
                     V = vi, 
                     slab = Authors,
                     data = df_meta,
                     random = ~ 1 | Authors/es.id, 
                     test = "t", 
                     mods = ~ Age + Clinical,
                     method = "REML")
summary(mod3)
convert_z2r(summary(mod3)$b)
calculate_estimates(mod3)

##################
mod4 <- rma.mv(yi = yi, 
                     V = vi, 
                     slab = Authors,
                     data = df_meta,
                     random = ~ 1 | Authors/es.id, 
                     test = "t", 
                     mods = ~ Age + Clinical + Summary_dim,
                     method = "REML")
summary(mod4)
convert_z2r(summary(mod4)$b)
calculate_estimates(mod4)
# df_meta |> select(Authors, Dimensions) significant dimensions are from ellis, not gkika 

##################
mod5 <- rma.mv(yi = yi, 
                     V = vi, 
                     slab = Authors,
                     data = df_meta,
                     random = ~ 1 | Authors/es.id, # Random effect/metacognition measure 
                     test = "t", 
                     mods = ~ Age + Clinical + Dimensions,
                     method = "REML")
summary(mod5)
convert_z2r(summary(mod5)$b)
calculate_estimates(mod5)

##################
mod6 <- rma.mv(yi = yi, 
                     V = vi, 
                     slab = Authors,
                     data = df_meta,
                     random = ~ 1 | Authors/es.id, # Random effect/metacognition measure 
                     test = "t", 
                     mods = ~ Age + Clinical + Summary_dim + Instrument_simpl,
                     method = "REML")
summary(mod6)
convert_z2r(summary(mod6)$b)
calculate_estimates(mod6)

##################
mod7 <- rma.mv(yi = yi, 
                     V = vi, 
                     slab = Authors,
                     data = df_meta,
                     random = ~ 1 | Authors/es.id, # Random effect/metacognition measure 
                     test = "t", 
                     mods = ~ Instrument_simpl,
                     method = "REML")
summary(mod7)
convert_z2r(summary(mod7)$b)
calculate_estimates(mod7)

```